# basics
model = "jsc-three-linear-layers"
dataset = "jsc"
task = "cls"

max_epochs = 10
batch_size = 512
learning_rate = 1e-2
accelerator = "cpu"
project = "jsc-three-linear-layers-test"
seed = 42
log_every_n_steps = 5
load_name = "../mase_output/three_linear_layers/software/training_ckpts/best.ckpt"
load_type = "pl"

[search.search_space]
name = "graph/quantize/channel_size_modifier"

[search.search_space.setup]
by = "name"

[search.search_space.seed.default.config]
# the only choice "NA" is used to indicate that layers are not quantized by default
name = ["NA"]
channel_multiplier = [1, 2, 4]

[search.search_space.seed.seq_blocks_2.config]
name = ["output_only"]
channel_multiplier = [1, 2, 4]

[search.search_space.seed.seq_blocks_4.config]
name = ["both"]
channel_multiplier = [1, 2, 4]
parent = ['seq_blocks_2']

[search.search_space.seed.seq_blocks_6.config]
name = ["input_only"]
channel_multiplier = [1, 2, 3, 5]
parent = ['seq_blocks_4']


[search.strategy]
name = "optuna"
eval_mode = false

# [search.strategy.sw_runner.basic_evaluation]
# data_loader = "val_dataloader"
# num_samples = 512

[search.strategy.sw_runner.basic_train]
name = "accuracy"
data_loader = "train_dataloader"
num_samples = 1000000
max_epochs = 10
lr_scheduler = "linear"
optimizer = "adam"
learning_rate = 1e-4
num_warmup_steps = 0

[search.strategy.hw_runner.average_bitwidth]
compare_to = 32 # compare to FP32

[search.strategy.setup]
n_jobs = 1
n_trials = 5
timeout = 20000
sampler = "bruteforce"
sum_scaled_metrics = true # single objective
direction = "maximize"

[search.strategy.metrics]
accuracy.scale = 1.0
accuracy.direction = "maximize"
